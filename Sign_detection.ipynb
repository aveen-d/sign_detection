{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sign_detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQGdr_v1fP5-",
        "colab_type": "text"
      },
      "source": [
        "dataset import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeZdSnFqfHxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "X=np.load(\"path to dataset features (X_c1.np)\")\n",
        "Y=np.load(\"path to dataset labels (Y_c1.np\")\n",
        "X=X/255.0\n",
        "plt.imshow(X[706])\n",
        "print(Y[706])\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42,stratify=Y)\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "#print(Y_test)\n",
        "a=[0,0,0,0,0,0,0,0,0,0]\n",
        "for i in range(Y_test.shape[0]):\n",
        "  a[int(Y_test[i])]=a[int(Y_test[i])]+1\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LiS9mM2fys4",
        "colab_type": "text"
      },
      "source": [
        "Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmHjvnrafS6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import Tensor\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
        "                                    Add, AveragePooling2D, Flatten, Dense\n",
        "from tensorflow.python.keras.models import Model\n",
        "\n",
        "initializer = tf.keras.initializers.HeNormal()\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  if (epoch%15)==0:\n",
        "    return lr * tf.math.exp(-0.1)\n",
        "  else:\n",
        "    return lr\n",
        "\n",
        "def relu_bn(inputs: Tensor) -> Tensor:\n",
        "    relu = ReLU()(inputs)\n",
        "    bn = BatchNormalization()(relu)\n",
        "    return bn\n",
        "\n",
        "def relu_u(inputs: Tensor) -> Tensor:\n",
        "    relu = ReLU()(inputs)\n",
        "    #bn = BatchNormalization()(relu)\n",
        "    return relu\n",
        "\n",
        "def bottleneck(x: Tensor, kernels:int, dilation: int) -> Tensor:\n",
        "    \n",
        "   \n",
        "    y = Conv2D(kernel_size=1,\n",
        "               strides= 1,\n",
        "               filters=int(kernels/4),\n",
        "               padding=\"same\",kernel_initializer=initializer)(x)\n",
        "    y = relu_bn(y)\n",
        "    \n",
        "    y = Conv2D(kernel_size=3,\n",
        "               strides=1,\n",
        "               filters=int(kernels/4),\n",
        "               padding=\"same\",kernel_initializer=initializer)(y)\n",
        "    y = relu_bn(y)\n",
        "    \n",
        "    y = Conv2D(kernel_size=1,\n",
        "               strides= 1,\n",
        "               filters=kernels,\n",
        "               padding=\"same\",kernel_initializer=initializer)(y)\n",
        "    y = relu_bn(y)\n",
        "    \n",
        "    out = Add()([x, y])\n",
        "    \n",
        "    y1 = Conv2D(kernel_size=1,\n",
        "               strides= 1,\n",
        "               filters=int(kernels/4),\n",
        "               padding=\"same\",kernel_initializer=initializer)(out)\n",
        "    y1 = relu_bn(y1)\n",
        "    \n",
        "    y1 = Conv2D(kernel_size=3,\n",
        "               strides=1,\n",
        "               filters=int(kernels/4),\n",
        "               dilation_rate=dilation,\n",
        "               padding=\"same\",kernel_initializer=initializer)(y1)\n",
        "    y1 = relu_bn(y1)\n",
        "    \n",
        "    y1 = Conv2D(kernel_size=1,\n",
        "               strides= 1,\n",
        "               filters=kernels,\n",
        "               padding=\"same\",kernel_initializer=initializer)(y1)\n",
        "    y1 = relu_bn(y1)\n",
        "    \n",
        "    out1 = Add()([out, y1])   \n",
        "\n",
        "    return out1\n",
        "\n",
        "def create_net():\n",
        "    \n",
        "    inputs = Input(shape=(256, 256, 3))\n",
        "    \n",
        "    t = Conv2D(kernel_size=3,\n",
        "               strides=2,\n",
        "               filters=64,\n",
        "               padding=\"valid\",kernel_initializer=initializer)(inputs)\n",
        "    t = relu_bn(t)\n",
        "    \n",
        "    t = Conv2D(kernel_size=3,\n",
        "               strides=2,\n",
        "               filters=128,\n",
        "               padding=\"valid\",kernel_initializer=initializer)(t)\n",
        "    t = relu_bn(t)\n",
        "    \n",
        "    t = bottleneck(t,kernels=128,dilation=2)\n",
        "    \n",
        "    t = Conv2D(kernel_size=3,\n",
        "               strides=2,\n",
        "               filters=256,\n",
        "               padding=\"valid\",kernel_initializer=initializer)(t)\n",
        "    t = relu_bn(t)\n",
        "    \n",
        "    t = bottleneck(t,kernels=256,dilation=4)\n",
        "    \n",
        "    \n",
        "    t = Conv2D(kernel_size=3,\n",
        "               strides=2,\n",
        "               filters=128,\n",
        "               padding=\"valid\",kernel_initializer=initializer)(t)\n",
        "    t = relu_bn(t)\n",
        "    \n",
        "    t = bottleneck(t,kernels=128,dilation=8)\n",
        "    \n",
        "    t = Conv2D(kernel_size=3,\n",
        "               strides=2,\n",
        "               filters=64,\n",
        "               padding=\"valid\",kernel_initializer=initializer)(t)\n",
        "    t = relu_bn(t)\n",
        "    \n",
        "    t=bottleneck(t,kernels=64,dilation=4)\n",
        "\n",
        "    t = Conv2D(kernel_size=3,\n",
        "               strides=2,\n",
        "               filters=16,\n",
        "               padding=\"valid\",kernel_initializer=initializer)(t)\n",
        "    t = relu_bn(t)\n",
        "\n",
        "\n",
        "    '''\n",
        "    t=bottleneck(t,kernels=32,dilation=2)\n",
        "\n",
        "    t = Conv2D(kernel_size=3,\n",
        "               strides=2,\n",
        "               filters=16,\n",
        "               padding=\"valid\")(t)\n",
        "    t = relu_bn(t)\n",
        "'''\n",
        "    t = Flatten()(t)\n",
        "    outputs = Dense(10, activation='softmax')(t)\n",
        "    \n",
        "    model = Model(inputs, outputs)\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.005),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uJN-2w2f5iM",
        "colab_type": "text"
      },
      "source": [
        "Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bAwkunYf2c_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = create_net()\n",
        "print(net.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ww2-ShpYf_55",
        "colab_type": "text"
      },
      "source": [
        "Training using keras .fit method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9goXvBnTf7GE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = create_net()\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "a=net.fit(X_train,Y_train,batch_size=8,epochs=40,validation_split=0.1,shuffle=True,callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jxt4BlvgFV5",
        "colab_type": "text"
      },
      "source": [
        "Testing the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN9KjxEdgCVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Evaluate on test data\")\n",
        "results = net.evaluate(X_test, Y_test, batch_size=1)\n",
        "print(\"test loss, test acc:\", results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sQWrXARgOoS",
        "colab_type": "text"
      },
      "source": [
        "Evaluating the model accuracy and confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7t2T7A0gMt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "y_=net.predict(X_test)\n",
        "y_pred=np.argmax(tf.nn.softmax(y_),axis=1)\n",
        "\n",
        "con_mat = tf.math.confusion_matrix(labels=Y_test, predictions=y_pred).numpy()\n",
        "\n",
        "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "classes=['0','1','2','3','4','5','6','7','8','9']\n",
        "con_mat_df = pd.DataFrame(con_mat_norm,\n",
        "                     index = classes, \n",
        "                     columns = classes)\n",
        "\n",
        "\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(Y_test, y_pred))\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(Y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VghMg4XcgW_p",
        "colab_type": "text"
      },
      "source": [
        "Save the model in  .h5 file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo4sb8s9gTXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.save('path to save model in .h5 format')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sp3aLnNKglFG",
        "colab_type": "text"
      },
      "source": [
        "Converting tensorflow model to tensorflow lite model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkp3jVWDgb6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import lite\n",
        "from tensorflow import keras\n",
        "mode = keras.models.load_model('path to model .h5 file')\n",
        "#mode.save('/gdrive/My Drive/final_model_.h5')\n",
        "converter = lite.TFLiteConverter.from_keras_model(mode)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "open('provide file name and path to store tflite model', 'wb').write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}